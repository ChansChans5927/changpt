import sys
import streamlit as st
from datetime import datetime
from langchain_ollama import ChatOllama
from langchain.agents import AgentExecutor, create_react_agent, Tool
from langchain_community.utilities import ArxivAPIWrapper
from langchain_community.utilities import GoogleSerperAPIWrapper
from langchain_community.tools import ArxivQueryRun, DuckDuckGoSearchRun
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° í…œí”Œë¦¿ íŒŒì¼ ê²½ë¡œ ì¶”ê°€
load_dotenv()
sys.path.append("../chat_prompt_templete.py")
from chat_prompt_templete import get_prompt_template

# Streamlit ì•± ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="llama3", page_icon="ğŸ¦™")
st.title("llama3")

#ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ì´ë“œë°”ì—ì„œ ì´ˆê¸°í™”
def initialize_parameters():
    st.sidebar.header("Model Parameters")
    temperature = st.sidebar.slider("Temperature", min_value=0.0, max_value=1.0, value=0.0, step=0.1)
    top_p = st.sidebar.slider("Top-p", min_value=0.0, max_value=1.0, value=0.9, step=0.1)
    return temperature, top_p

#ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  ë„êµ¬ë“¤ì„ ìƒì„±í•˜ê³  ë°˜í™˜
def create_tools():
    search_tool = DuckDuckGoSearchRun(name="Search")
    
    arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)
    arxiv_tool = ArxivQueryRun(api_wrapper=arxiv_wrapper)
    
    date_tool = Tool.from_function(
        func=lambda x: datetime.now().strftime("%A, %B %d, %Y"),
        name="Current Date",
        description="Useful for when you are need to find the current date and/or time",
    )

    google_serper_tool = Tool.from_function(
        func=GoogleSerperAPIWrapper().run,
        name="Google Search",
        description="Search using Google Serper API to find precise information"
    )
    
    return [search_tool, arxiv_tool, google_serper_tool, date_tool]

#ì—ì´ì „íŠ¸ ì‹¤í–‰ìë¥¼ ìƒì„±í•˜ê³  ë°˜í™˜
def create_agent_executor(tools, temperature, top_p):
    llama = ChatOllama(
        model="llama3:latest",
        temperature=temperature,
        top_p=top_p
    )
    
    react_agent = create_react_agent(
        llm=llama,
        tools=tools,
        prompt=get_prompt_template()
    )
    
    return AgentExecutor(
        agent=react_agent,
        tools=tools,
        handle_parsing_errors=True,
        verbose=True
    )

#ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ì±„íŒ… ê¸°ë¡ì„ í™”ë©´ì— í‘œì‹œ
def display_chat_history():
    messages = st.session_state.get("ollama_messages", [])
    for msg in messages:
        st.chat_message(msg["role"]).write(msg["content"])
    return messages

#ì‚¬ìš©ìì˜ ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  assistantì˜ ì‘ë‹µì„ í‘œì‹œ
def handle_chat_interaction(user_input, agent_executor, messages):
    messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)
        
    with st.chat_message("assistant"):
        with st.spinner("Searching..."):
            search_results = agent_executor.invoke(
                {"input": user_input, "chat_history": messages}
            )
        st.write(search_results["output"])
        
    messages.append({"role": "assistant", "content": search_results["output"]})
    st.session_state.ollama_messages = messages

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "ollama_messages" not in st.session_state:
    st.session_state.ollama_messages = []

# íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”
temperature, top_p = initialize_parameters()
# ì—ì´ì „íŠ¸ ë„êµ¬ ìƒì„±
tools = create_tools()
# ì—ì´ì „íŠ¸ ì‹¤í–‰ì ìƒì„±
agent_executor = create_agent_executor(tools, temperature, top_p)

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
messages = display_chat_history()

# ì‚¬ìš©ìì˜ ì…ë ¥ ì²˜ë¦¬
user_input = st.chat_input("Type your message here...")
if user_input:
    handle_chat_interaction(user_input, agent_executor, messages)